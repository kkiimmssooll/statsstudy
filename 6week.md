# ch5. 분류
> 결과가 있는 데이터로 모델 학습->결과를 모르는 데이터에 모델을 적용하는 지도 학습습 

## 5.1 나이브 베이즈
```
✅ 용어
- 
```
> 주어진 결과에 대해 예측변수값을 관찰할 확률을 사용하여, 예측변수가 주어졌을 때 결과 Y=i를 관찰할 확률

> 표준 나이브 베이즈 알고리즘에서 예측변수는 범주형 변수여야 함

```
💡책에 있는 예제 기반 지피티가 쉽게 설명해준 것,,💡
- 어떤 사람이 대출 신청을 함. 이 사람의 정보: 나이 30, 대출목적은 자동차 구매, 소득수준은 중간.
- 이 사람이 상환을 잘 할지(default=No) 안 할지(default=Yes)를 예측해야 함.
- 각 정보(나이, 목적, 소득)가 상환 여부와 얼마나 관련 있는지 과거 데이터에서 확률로 계산함.
- 그리고 베이즈 정리를 이용해, 상환할 확률 vs 못할 확률 중 높은 쪽을 선택!
```

## 5.2 판별분석
```
✅ 용어
- 공분산 : 하나의 변수가 다른 변수와 함께 변화하는 정도
- 판별함수 : 예측변수에 적용했을 때 클래스 구분을 최대화하는 함수
- 판별 가중치 : 판별함수를 적용하여 얻은 점수->어떤 클래스에 속할 확률을 추정하는 데 사용
```
>  가장 일반적으로 사용되는 것은 선형판별분석(LDA)이지만 트리 모델, 로지스틱 회귀가 나온 이후 사용빈도가 떨어짐

> 변수가 범주형이든 연속형이든 상관없음

### 공분산
- 분모에 N-1 사용
- 양수는 양의 관계, 음수는 음의 관계를 의미

### 선형판별
- 그룹 안 편차와 그룹 간 편차를 구분
- 내부(그룹 안) 제곱합에 대한 사이(그룹 간) 제곱합의 비율을 최대화하는 것을 목표로 함
    - 내부 제곱합은 최소화, 사이 제곱합은 최대화
-> 실선을 이용해 예측변수 영역을 두 부분으로 나눔, 멀리 떨어진 예측 결과일수록 신뢰도가 높음

## 5.3 로지스틱 회귀
```
✅ 용어
- 로짓(logit) : 무한대의 범위에서 어떤 클래스에 속할 확률을 결정하는 함수
- 오즈(odds) : 실패에 대한 성공 비율
- 로그 오즈 : 변환 모델의 응답변수, 이 값으로 확률을 구함
```
### 로지스틱 반응 함수와 로짓
> 로지스틱 함수는 예측하려는 결과가 0아니면 1일 때 사용하는 함수

![study_1](/stats_study/5.3.png)
```
로지스틱에서 예측하고 싶은 건 확률=>0과 1사이의 값
하지만 위 선형회귀처럼 식을 작성하면 예측값이 -무한~+무한까지, 0보다 작거나 1보다 큰 값이 나올 수 있음
```
- 로지스틱 반응(역 로짓)
![study_2](/stats_study/5.3.1.png)
> 선형식->확률

> 위 선형식에 로지스틱 함수를 씌우면 입력값이 아무리 커지거나 작아져도 출력값은 0~1사이로 유지

- 오즈비
- 로그 오즈 함수(로짓 함수)
> 확률->선형식

### 로지스틱 회귀와 GLM(일반화 선형 모형)
> 로지스틱 회귀는 선형회귀를 확장한 GLM의 특별한 사례

> 일반적 선형회귀는 정규분포+직선 가정/GLM은 선형회귀의 확장판으로 확률분포가 다르거나 선형으로 설명하기 어려운 데이터도 다룰 수 있음

### 일반화선형모형
```
확률분포 또는 분포군(로지스틱은 이항분포)
응답을 예측변수에 매핑하는 연결 함수(로지스틱은은 로짓)
```
### 계수와 오즈비 해석

### 선형회귀와 로지스틱 회귀
1. 공통점
    - 예측변수와 응답변수를 선형 관계로 가정
2. 차이점
    - 모델 피팅 방식
    - 모델에서 잔차의 특징과 분석

### 모델 평가하기
> 모델이 새로운 데이터를 얼마나 정확하게 분류하는가(다른 분류 방법들과 똑같다!)


## 5.4 분류 모델 평가하기
### 혼동 행렬
![study_3](/stats_study/5.4.png)
1. 정밀도->예측된 양성 결과의 정확도
    참 양성/(참 양성+거짓 양성)
2. 재현율(민감도)->양성 결과를 예측하는 능력
    참 양성/(참 양성+거짓 음성)
3. 특이도->음성 결과를 예측하는 능력
    참 음성/(참 음성+거짓 양성)
```
ROC
재현도와 특이도사이의 트레이드오프 관계를 나타내는 지표
skleran.metrics.roc_curve

AUC
ROC의 곡선 아래 면적
모델이 1과 0을 구분하는 능력을 보여주기 위해 가장 보편적으로 사용되는 지표
값이 높을수록 더 잘 분류함
AUC=1이라는 것은 0을 1로 잘못 예측하는 경우 없이 1을 정확히 분류
sklearn.metrics_roc_auc_curve
```

⚠️ 희귀 케이스(1이 되는 케이스가 드문 경우)에는 모델이 거의 모든 걸 0으로 예측해도 정확도가 높게 나올 수 있음
-> 그래서 0.5보다 낮은 컷오프값(0.3,0.4)을 설정하여 1을 놓치지 않게 함
-> 하지만 이러면 확률이 낮은 것도 1로 분류하게 되어 1을 과대평가하게 됨
-> *리프트*를 활용해 컷오프를 찾는 것 

**리프트**
모델이 무작위 추측보다 특정 결과(1)를 얼마나 더 효과적으로 예측했는지를 나타내는 비율
상위 10% 레코드에서 무작위가 0.1% 정확도, 모델이 0.3% 정확도라면 상위 10%에서 3의 리프트를 갖는 것
![study_4](/stats_study/5.4.1.png)

## 5.5 불균형 데이터 다루기
> 온라인 구매, 불균형 사기 등 하나에 치우치는 케이스

1. 과소표본추출(다운샘플링)
- 다수의 클래스에 속한 데이터 중 중복된 레코드가 많을 것이라는 사실에서 출발

2. 과잉표본추출(업샘플링)
- 부트스트랩으로 희귀 클래스 데이터를 생성하는 것
- 희귀 클래스에 가중치를 부여(weight)